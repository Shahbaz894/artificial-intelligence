{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000182F9354110> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000182F967A190> root_client=<openai.OpenAI object at 0x00000182F7BFFB50> root_async_client=<openai.AsyncOpenAI object at 0x00000182F9665E10> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "# result=llm.invoke(\"what is genertaive ai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a simple explanation of vector embeddings:\n",
      "\n",
      "**Imagine a map of a high-dimensional space to a lower-dimensional space.** This is what a vector embedding does. It takes a complex piece of data (like a sentence, a picture, or a piece of music) and compresses it into a smaller, more manageable representation.\n",
      "\n",
      "**Key points:**\n",
      "\n",
      "* **High-dimensional space:** This is the original, high-dimensional space where the data lives. It's like a vast library of books, each book representing a different piece of information.\n",
      "* **Lower-dimensional space:** This is a smaller, more manageable space like a library bookshelf. It's like a smaller section of the library where books are shelved.\n",
      "* **Embedding:** This is a process of mapping the data from the high-dimensional space to the lower-dimensional space.\n",
      "* **Compression:** In the embedding process, some information is lost and compressed, while other information is preserved. This makes the data easier to work with and store.\n",
      "* **Applications:** Vector embeddings have many applications, including:\n",
      "    * **Natural Language Processing (NLP):** They can be used to analyze and understand text and speech.\n",
      "    * **Image recognition:** They can be used to identify objects in images.\n",
      "    * **Music recommendation:** They can be used to recommend music based on your taste.\n",
      "    * **Drug discovery:** They can be used to identify new drug targets.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "* Vector embeddings are a way to represent complex data in a smaller, more manageable space.\n",
      "* This allows us to perform various tasks with the data more easily.\n",
      "* There are different types of embeddings, each suited for different purposes.\n",
      "\n",
      "**Additional points:**\n",
      "\n",
      "* Think of vector embeddings as a \"hash code\" that tells you where in the lower-dimensional space a piece of data is located.\n",
      "* Embeddings can be linear or nonlinear, depending on the chosen algorithm.\n",
      "* They are a powerful tool in machine learning that has revolutionized various fields.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "try:\n",
    "    # Initialize the Ollama model\n",
    "    llm = Ollama(model='gemma:2b')  # Replace 'gemma:2b' with the correct model name\n",
    "\n",
    "    # Create a prompt template\n",
    "    prompt_template = PromptTemplate(template=\"Can you explain the concept of vector embeddings in simple terms?\")\n",
    "    \n",
    "    # Format the prompt (if necessary)\n",
    "    formatted_prompt = prompt_template.format()  # This may depend on how PromptTemplate is used\n",
    "\n",
    "    # Generate a response\n",
    "    response = llm(formatted_prompt)\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
