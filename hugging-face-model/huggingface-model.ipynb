{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "e:\\artificial_intelligence\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Access the token\n",
    "token = os.getenv(\"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\")\n",
    "\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token retrieved successfully\n",
      " and how does it work?\n",
      "\n",
      "Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\n",
      "\n",
      "Machine learning algorithms build a mathematical model based on sample data, known as \"training data,\" in order to make predictions or decisions without being specifically programmed to perform the task. These algorithms can be categorized as supervised, unsupervised, semi-supervised, or reinforcement learning.\n",
      "\n",
      "Supervised learning involves providing the algorithm with labeled data, meaning the data comes with a known output, and the algorithm learns to map inputs to outputs based on the examples it is given. Common applications of supervised learning include email spam filtering, image recognition, and speech recognition.\n",
      "\n",
      "Unsupervised learning involves providing the algorithm with unlabeled data, meaning the data does not have a known output, and the algorithm must find patterns and relationships within the data on its own. Common applications of unsupervised learning include clustering and anomaly detection.\n",
      "\n",
      "Semi-supervised learning is a combination of supervised and unsupervised learning, where the algorithm is given a small amount of labeled data and a large amount of unlabeled data to learn from.\n",
      "\n",
      "Reinforcement learning involves the algorithm learning to make decisions by taking actions in an environment and receiving feedback in the form of rewards or penalties. The algorithm learns to maximize its rewards over time by adjusting its actions based on the feedback it receives. Common applications of reinforcement learning include game playing and robotics.\n",
      "\n",
      "Machine learning models are trained on large datasets using powerful computers and then deployed to make predictions or decisions on new, unseen data. The accuracy and performance of machine learning models depend on the quality and quantity of the training data, as well as the choice of algorithm and its parameters.\n",
      "\n",
      "Machine learning is being used in a wide range of applications, from recommending products to users on e-commerce websites to diagnosing diseases in medical imaging. It is a rapidly evolving field with many exciting possibilities for the future.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the token from environment variable\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if token is None:\n",
    "    raise ValueError(\"HF_TOKEN not found in environment variables.\")\n",
    "else:\n",
    "    print(\"Token retrieved successfully\")\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Initialize the HuggingFaceEndpoint with the token\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=128, temperature=0.7, token=token)\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(\"What is machine learning\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "question='who won the circuit world cup 2011'\n",
    "template={'question':question}\n",
    "Answer='Lest think step by step'\n",
    "prompt=PromptTemplate(template=template,input_variables=['question'])\n",
    "input_variable=['question' ] template='Question :{question}\\nAwnser : lets think step by step'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
